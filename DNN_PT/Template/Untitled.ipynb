{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71739bf5-d774-4b39-b782-2fd11c8a203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet101, resnet50, vgg16, alexnet, inception_v3\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_random_subset_indices(num_samples, dataset_size):\n",
    "    return random.sample(range(dataset_size), num_samples)\n",
    "\n",
    "\n",
    "def create_dataset(model_name):\n",
    "    if model_name == \"LeNet\":\n",
    "        input_size = 32\n",
    "    elif model_name == \"Inception-V3\":\n",
    "        input_size = 299\n",
    "    else:\n",
    "        input_size = 224\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(os.path.join(\"/lus/eagle/projects/datascience/ImageNet/ILSVRC/Data/CLS-LOC\", \"train\"), transform=train_transform)\n",
    "\n",
    "    num_samples = 10000\n",
    "    train_indices = get_random_subset_indices(num_samples, len(train_dataset))\n",
    "    small_train_dataset = Subset(train_dataset, train_indices)\n",
    "    return small_train_dataset\n",
    "\n",
    "\n",
    "def build_model(model_name,GPU_selection,share):\n",
    "    if model_name == \"ResNet-101\":\n",
    "        model = resnet101(weights=None)\n",
    "    elif model_name == \"ResNet-50\":\n",
    "        model = resnet50(weights=None)\n",
    "    elif model_name == \"VGG-16\":\n",
    "        model = vgg16(weights=None)\n",
    "    elif model_name == \"AlexNet\":\n",
    "        model = alexnet(weights=None)\n",
    "    elif model_name == \"LeNet\":\n",
    "        model = LeNet()\n",
    "    elif model_name == \"Inception-V3\":\n",
    "        model = inception_v3(weights=None, aux_logits=True)\n",
    "        num_ftrs = model.AuxLogits.fc.in_features\n",
    "        model.AuxLogits.fc = nn.Linear(num_ftrs, 1000)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, 1000)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    device = torch.device(\"cuda:\" + str(GPU_selection[0]) if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    if share==1:\n",
    "        model = nn.DataParallel(model, device_ids=[int(gpu) for gpu in GPU_selection])   \n",
    "    else:\n",
    "        model = nn.DataParallel(model)\n",
    "    return model, criterion, optimizer, device\n",
    "\n",
    "\n",
    "def create_dataLoader(model_name, batch_size=256, workers=8):\n",
    "    return DataLoader(create_dataset(model_name), batch_size=batch_size, num_workers=workers, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "def select_device(selected_gpus):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, selected_gpus))\n",
    "\n",
    "\n",
    "def train_one_epoch(model_name, model, criterion, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "    total_images = 0\n",
    "    start_time = time.time()\n",
    "    start_time_dataLoad = time.time()\n",
    "    end_time_dataLoad = 0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if model_name == \"Inception-V3\":\n",
    "            outputs, aux_outputs = model(inputs)\n",
    "            loss1 = criterion(outputs, labels)\n",
    "            loss2 = criterion(aux_outputs, labels)\n",
    "            loss = loss1 + 0.4 * loss2\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.to(outputs.device))\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_images += inputs.size(0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    images_per_second = total_images / (end_time - start_time)\n",
    "    dataLoad_time = end_time_dataLoad - start_time_dataLoad\n",
    "    return int(images_per_second), end_time - start_time\n",
    "\n",
    "\n",
    "\n",
    "def train(model_name, batch_size=256, GPU_selection=[0, 1], epoch=5, num_workers=8,output=\"default\",share=0):\n",
    "    num_epochs = epoch\n",
    "    train_loader = create_dataLoader(model_name, batch_size, num_workers)\n",
    "        \n",
    "    model, criterion, optimizer, device = build_model(model_name, GPU_selection=GPU_selection, share=share)\n",
    "   \n",
    "    images_per_second_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        images_per_second, epoch_duration = train_one_epoch(model_name, model, criterion, optimizer, train_loader, device)\n",
    "        if epoch > 0:  # Skip the first epoch\n",
    "            images_per_second_list.append(images_per_second)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Duration: {epoch_duration:.2f}s, Images/s: {images_per_second}\")\n",
    "\n",
    "    avg_images_per_second = sum(images_per_second_list) / len(images_per_second_list)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    num_gpus = len(GPU_selection)\n",
    "    result = [model_name, batch_size, num_workers, num_gpus, avg_images_per_second]\n",
    "\n",
    "    csv_file = \"../result/\" + output\n",
    "    if not os.path.isfile(csv_file):\n",
    "        with open(csv_file, \"w\", newline=\"\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            header = [\"Model\", \"Batch_Size\", \"Num_Workers\", \"Num_GPUs\", \"Images/s\"]\n",
    "            csv_writer.writerow(header)\n",
    "\n",
    "    # Append the results to the CSV file\n",
    "    with open(csv_file, \"a\", newline=\"\") as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(result)\n",
    "\n",
    "\n",
    "# def main(args):\n",
    "#     model_name = args.model_name\n",
    "#     batch_size = args.batch_size\n",
    "#     num_workers = args.number_worker\n",
    "#     output = args.output\n",
    "#     GPU_selection = [int(gpu) for gpu in args.GPU_selection.split(\",\")]\n",
    "#     node_share = args.share\n",
    "    \n",
    "#     if(node_share==0):\n",
    "#         select_device(GPU_selection)\n",
    "\n",
    "#     train(model_name, batch_size=batch_size, GPU_selection=GPU_selection, num_workers=num_workers, output=output,share=node_share)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--model_name\", type=str, default=\"ResNet-50\", help=\"Choose the model: Inception-V3, ResNet-101, ResNet-50, VGG-16, AlexNet, LeNet\")\n",
    "#     parser.add_argument(\"--batch_size\", type=int, default=256, help=\"Batch size for training (default: 256)\")\n",
    "#     parser.add_argument(\"--number_worker\", type=int, default=8, help=\"Number of workers for data loading (default: 8)\")\n",
    "#     parser.add_argument(\"--GPU_selection\", type=str, default=\"0,1\", help=\"Comma-separated list of GPU indices to use (default: 0,1)\")\n",
    "#     parser.add_argument(\"--output\", type=str, default=\"result\", help=\"speficy the csv output file\")\n",
    "#     parser.add_argument(\"--share\", type=int, default=1, help=\"Node-sharing\")\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca20548-40bb-4e43-b106-c6d717b3299a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
