{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd22f223-4bff-4c2b-8c1a-80aa546538fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "def get_random_subset_indices(num_samples, dataset_size):\n",
    "    return random.sample(range(dataset_size), num_samples)\n",
    "\n",
    "\n",
    "def create_dataset():\n",
    "     # Data augmentation and normalization for training\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(os.path.join(\"/lus/eagle/projects/datascience/ImageNet/ILSVRC/Data/CLS-LOC\", \"train\"), transform=train_transform)\n",
    "\n",
    "    num_samples = 10000\n",
    "\n",
    "    train_indices = get_random_subset_indices(num_samples, len(train_dataset))\n",
    "    small_train_dataset = Subset(train_dataset, train_indices)\n",
    "    return small_train_dataset\n",
    "\n",
    "def build_model():\n",
    "    model = vgg16(weights=None)\n",
    "    num_ftrs = model.classifier[6].in_features\n",
    "    model.classifier[6] = nn.Linear(num_ftrs, 1000)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    return model, criterion, optimizer, device\n",
    "\n",
    "\n",
    "def create_dataLoader(batch_size=128, workers=4):\n",
    "    return DataLoader(create_dataset(), batch_size=batch_size, num_workers=workers, shuffle=True, pin_memory=True)\n",
    "\n",
    "def select_device(selected_gpus):\n",
    "     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, selected_gpus))\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "\n",
    "    total_images = 0\n",
    "    start_time = time.time()\n",
    "    start_time_dataLoad = time.time()\n",
    "    end_time_dataLoad = 0\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_images += inputs.size(0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    images_per_second = total_images / (end_time - start_time)\n",
    "    dataLoad_time = end_time_dataLoad - start_time_dataLoad\n",
    "    return int(images_per_second), end_time-start_time\n",
    "\n",
    "\n",
    "def train(batch_size=256, GPU_selection=[0, 1], epoch=5, num_workers=8):\n",
    "    \n",
    "    num_epochs = epoch  # Adjust this value according to your needs\n",
    "    train_loader = create_dataLoader(batch_size, num_workers)\n",
    "    select_device(GPU_selection)\n",
    "    model,criterion,optimizer,device = build_model()\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        images_per_second, epoch_duration = train_one_epoch(model, criterion, optimizer, train_loader, device)\n",
    "      \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}],Duration: {epoch_duration:.2f}s, Images/s: {images_per_second}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e9a47-4fa1-40a3-9189-f885f152ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size=64, GPU_selection=[0], epoch=5, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81842c-bc6c-4555-840a-77795d1c6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size=64, GPU_selection=[0,1], epoch=5, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fba88b-8573-4336-b818-ef47bb5d0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(batch_size=64, GPU_selection=[0,1,2], epoch=5, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63441f3e-448d-468f-a361-4cf71b03c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5],Duration: 72.02s, Images/s: 138\n",
      "Epoch [2/5],Duration: 9.36s, Images/s: 1068\n",
      "Epoch [3/5],Duration: 9.23s, Images/s: 1083\n",
      "Epoch [4/5],Duration: 9.71s, Images/s: 1029\n",
      "Epoch [5/5],Duration: 9.14s, Images/s: 1094\n"
     ]
    }
   ],
   "source": [
    "train(batch_size=256, GPU_selection=[0,1,2,3], epoch=5, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e3648-5558-4b06-820e-5d50b24e32aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
